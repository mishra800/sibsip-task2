{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4dbd70-560f-4ecd-a210-03fa84331da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Necessary python libraries\n",
    "\n",
    "import pandas as pa\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b656e71d-f70b-42bc-a7d6-edc09d32ea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Region         Date  Frequency   Estimated Unemployment Rate (%)  \\\n",
      "0    Andhra Pradesh   31-05-2019    Monthly                              3.65   \n",
      "1    Andhra Pradesh   30-06-2019    Monthly                              3.05   \n",
      "2    Andhra Pradesh   31-07-2019    Monthly                              3.75   \n",
      "3    Andhra Pradesh   31-08-2019    Monthly                              3.32   \n",
      "4    Andhra Pradesh   30-09-2019    Monthly                              5.17   \n",
      "..              ...          ...        ...                               ...   \n",
      "763             NaN          NaN        NaN                               NaN   \n",
      "764             NaN          NaN        NaN                               NaN   \n",
      "765             NaN          NaN        NaN                               NaN   \n",
      "766             NaN          NaN        NaN                               NaN   \n",
      "767             NaN          NaN        NaN                               NaN   \n",
      "\n",
      "      Estimated Employed   Estimated Labour Participation Rate (%)   Area  \n",
      "0             11999139.0                                     43.24  Rural  \n",
      "1             11755881.0                                     42.05  Rural  \n",
      "2             12086707.0                                     43.50  Rural  \n",
      "3             12285693.0                                     43.97  Rural  \n",
      "4             12256762.0                                     44.68  Rural  \n",
      "..                   ...                                       ...    ...  \n",
      "763                  NaN                                       NaN    NaN  \n",
      "764                  NaN                                       NaN    NaN  \n",
      "765                  NaN                                       NaN    NaN  \n",
      "766                  NaN                                       NaN    NaN  \n",
      "767                  NaN                                       NaN    NaN  \n",
      "\n",
      "[768 rows x 7 columns]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Region                                    740 non-null    object \n",
      " 1    Date                                     740 non-null    object \n",
      " 2    Frequency                                740 non-null    object \n",
      " 3    Estimated Unemployment Rate (%)          740 non-null    float64\n",
      " 4    Estimated Employed                       740 non-null    float64\n",
      " 5    Estimated Labour Participation Rate (%)  740 non-null    float64\n",
      " 6   Area                                      740 non-null    object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 42.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "classify1=pa.read_csv(\"Unemployment in India.csv\")\n",
    "# This dataset contains all months data of year 2019\n",
    "print(classify1)\n",
    "print()\n",
    "classify1.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e442ca-2a38-43fd-8a12-07bc28c654d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "             Region         Date  Frequency   Estimated Unemployment Rate (%)  \\\n",
      "0    Andhra Pradesh   31-01-2020          M                              5.48   \n",
      "1    Andhra Pradesh   29-02-2020          M                              5.83   \n",
      "2    Andhra Pradesh   31-03-2020          M                              5.79   \n",
      "3    Andhra Pradesh   30-04-2020          M                             20.51   \n",
      "4    Andhra Pradesh   31-05-2020          M                             17.43   \n",
      "..              ...          ...        ...                               ...   \n",
      "262     West Bengal   30-06-2020          M                              7.29   \n",
      "263     West Bengal   31-07-2020          M                              6.83   \n",
      "264     West Bengal   31-08-2020          M                             14.87   \n",
      "265     West Bengal   30-09-2020          M                              9.35   \n",
      "266     West Bengal   31-10-2020          M                              9.98   \n",
      "\n",
      "      Estimated Employed   Estimated Labour Participation Rate (%) Region.1  \\\n",
      "0               16635535                                     41.02    South   \n",
      "1               16545652                                     40.90    South   \n",
      "2               15881197                                     39.18    South   \n",
      "3               11336911                                     33.10    South   \n",
      "4               12988845                                     36.46    South   \n",
      "..                   ...                                       ...      ...   \n",
      "262             30726310                                     40.39     East   \n",
      "263             35372506                                     46.17     East   \n",
      "264             33298644                                     47.48     East   \n",
      "265             35707239                                     47.73     East   \n",
      "266             33962549                                     45.63     East   \n",
      "\n",
      "     longitude  latitude  \n",
      "0      15.9129    79.740  \n",
      "1      15.9129    79.740  \n",
      "2      15.9129    79.740  \n",
      "3      15.9129    79.740  \n",
      "4      15.9129    79.740  \n",
      "..         ...       ...  \n",
      "262    22.9868    87.855  \n",
      "263    22.9868    87.855  \n",
      "264    22.9868    87.855  \n",
      "265    22.9868    87.855  \n",
      "266    22.9868    87.855  \n",
      "\n",
      "[267 rows x 9 columns]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 267 entries, 0 to 266\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Region                                    267 non-null    object \n",
      " 1    Date                                     267 non-null    object \n",
      " 2    Frequency                                267 non-null    object \n",
      " 3    Estimated Unemployment Rate (%)          267 non-null    float64\n",
      " 4    Estimated Employed                       267 non-null    int64  \n",
      " 5    Estimated Labour Participation Rate (%)  267 non-null    float64\n",
      " 6   Region.1                                  267 non-null    object \n",
      " 7   longitude                                 267 non-null    float64\n",
      " 8   latitude                                  267 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# THis method will give exact data information type and non-null values of first dataset\n",
    "# It has total 768 data points and 7 columns\n",
    "# So, lets lookout another dataset which will help us.\n",
    "classify2=pa.read_csv(\"Unemployment_Rate_upto_11_2020.csv\")\n",
    "print()\n",
    "print(classify2)\n",
    "# While this dataset contains first 10 months of the year 2020\n",
    "print()\n",
    "classify2.info()\n",
    "# This will give us the data information about which datatype and non- null values of dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04e73c5-6a25-4d39-b3bd-f7733cf0598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Region                                      28\n",
      " Date                                       28\n",
      " Frequency                                  28\n",
      " Estimated Unemployment Rate (%)            28\n",
      " Estimated Employed                         28\n",
      " Estimated Labour Participation Rate (%)    28\n",
      "Area                                        28\n",
      "dtype: int64\n",
      "\n",
      "Region                                      0\n",
      " Date                                       0\n",
      " Frequency                                  0\n",
      " Estimated Unemployment Rate (%)            0\n",
      " Estimated Employed                         0\n",
      " Estimated Labour Participation Rate (%)    0\n",
      "Region.1                                    0\n",
      "longitude                                   0\n",
      "latitude                                    0\n",
      "dtype: int64\n",
      "\n",
      "Region                                      0\n",
      " Date                                       0\n",
      " Frequency                                  0\n",
      " Estimated Unemployment Rate (%)            0\n",
      " Estimated Employed                         0\n",
      " Estimated Labour Participation Rate (%)    0\n",
      "Area                                        0\n",
      "dtype: int64\n",
      "\n",
      "(740, 7)\n",
      "(267, 9)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing and Data Cleaning\n",
    "\n",
    "# Lets check whether the data sets have any null points in dataset 1\n",
    "print()\n",
    "print(classify1.isnull().sum())\n",
    "# lets us check we can find any null data in the dataset 2\n",
    "print()\n",
    "print(classify2.isnull().sum())\n",
    "# As we see that the classify1 have sum null values so lets drop them\n",
    "classify1=classify1.dropna()\n",
    "print()\n",
    "print(classify1.isnull().sum())\n",
    "print()\n",
    "print(classify1.shape)\n",
    "print(classify2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a45366-1ee7-4d54-ad58-e5c5461a31c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 740 entries, 0 to 753\n",
      "Data columns (total 7 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   State                                740 non-null    object \n",
      " 1   Date                                 740 non-null    object \n",
      " 2   Frequency                            740 non-null    object \n",
      " 3   Estimated Unemployment Rate          740 non-null    float64\n",
      " 4   Estimated Employed                   740 non-null    float64\n",
      " 5   Estimated Labour Participation Rate  740 non-null    float64\n",
      " 6   Area                                 740 non-null    object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 46.2+ KB\n",
      "None \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 267 entries, 0 to 266\n",
      "Data columns (total 9 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   State                                267 non-null    object \n",
      " 1   Date                                 267 non-null    object \n",
      " 2   Frequency                            267 non-null    object \n",
      " 3   Estimated Unemployment Rate          267 non-null    float64\n",
      " 4   Estimated Employed                   267 non-null    int64  \n",
      " 5   Estimated Labour Participation Rate  267 non-null    float64\n",
      " 6   Region                               267 non-null    object \n",
      " 7   Longitude                            267 non-null    float64\n",
      " 8   Latitude                             267 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 18.9+ KB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As we can see that there are no null values in the both dataset\n",
    "# For our better understanding , we will rename the columns of our data to simplest\n",
    "classify1.columns=[\"State\",\"Date\",\"Frequency\",\"Estimated Unemployment Rate\",\"Estimated Employed\",\"Estimated Labour Participation Rate\",\"Area\"]\n",
    "classify2.columns=[\"State\",\"Date\",\"Frequency\",\"Estimated Unemployment Rate\",\"Estimated Employed\",\"Estimated Labour Participation Rate\",\"Region\",\"Longitude\",\"Latitude\"]\n",
    "# Lets check whether changes are applied or not\n",
    "print(classify1.info(),\"\\n\")\n",
    "print(classify2.info(),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03fe5758-b6a7-485c-9b3a-70bc4dffde7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Estimated Unemployment Rate  Estimated Employed  \\\n",
      "count                   740.000000        7.400000e+02   \n",
      "mean                     11.787946        7.204460e+06   \n",
      "std                      10.721298        8.087988e+06   \n",
      "min                       0.000000        4.942000e+04   \n",
      "25%                       4.657500        1.190404e+06   \n",
      "50%                       8.350000        4.744178e+06   \n",
      "75%                      15.887500        1.127549e+07   \n",
      "max                      76.740000        4.577751e+07   \n",
      "\n",
      "       Estimated Labour Participation Rate  \n",
      "count                           740.000000  \n",
      "mean                             42.630122  \n",
      "std                               8.111094  \n",
      "min                              13.330000  \n",
      "25%                              38.062500  \n",
      "50%                              41.160000  \n",
      "75%                              45.505000  \n",
      "max                              72.570000   \n",
      "\n",
      "       Estimated Unemployment Rate  Estimated Employed  \\\n",
      "count                   267.000000        2.670000e+02   \n",
      "mean                     12.236929        1.396211e+07   \n",
      "std                      10.803283        1.336632e+07   \n",
      "min                       0.500000        1.175420e+05   \n",
      "25%                       4.845000        2.838930e+06   \n",
      "50%                       9.650000        9.732417e+06   \n",
      "75%                      16.755000        2.187869e+07   \n",
      "max                      75.850000        5.943376e+07   \n",
      "\n",
      "       Estimated Labour Participation Rate   Longitude    Latitude  \n",
      "count                           267.000000  267.000000  267.000000  \n",
      "mean                             41.681573   22.826048   80.532425  \n",
      "std                               7.845419    6.270731    5.831738  \n",
      "min                              16.770000   10.850500   71.192400  \n",
      "25%                              37.265000   18.112400   76.085600  \n",
      "50%                              40.390000   23.610200   79.019300  \n",
      "75%                              44.055000   27.278400   85.279900  \n",
      "max                              69.690000   33.778200   92.937600   \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Andhra Pradesh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classify2\u001b[38;5;241m.\u001b[39mdescribe(),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# It will give us the statistical information about the data\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassify1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(classify2\u001b[38;5;241m.\u001b[39mcorr())\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Let us take correlation of the data so we can use that information to analyze the data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:10707\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  10705\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  10706\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 10707\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  10709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10710\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:1892\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1891\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1892\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1894\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1713\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1715\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Andhra Pradesh'"
     ]
    }
   ],
   "source": [
    "#Visualization of the data\n",
    "\n",
    "print(classify1.describe(),\"\\n\")\n",
    "print(classify2.describe(),\"\\n\")\n",
    "# It will give us the statistical information about the data\n",
    "\n",
    "print(classify1.corr())\n",
    "print(classify2.corr())\n",
    "# Let us take correlation of the data so we can use that information to analyze the data\n",
    "\n",
    "print(classify1[\"State\"].value_counts(),\"\\n\")\n",
    "print(classify2['State'].value_counts(),\"\\n\")\n",
    "# This will give us the data about each state frequency in the dataset.\n",
    "\n",
    "# let's see the distruibution of the average unemployment rates across areas of the year 2019\n",
    "average_of_regions1=classify1.groupby(\"Area\")[\"Estimated Unemployment Rate\"].mean()\n",
    "average_of_regions1.plot(kind='pie',autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Area-wise Average Unemployment Rate of year 2019')\n",
    "plt.show()\n",
    "\n",
    "# let's see the distruibution of the average unemployment rates across regions of the year 2020\n",
    "average_of_regions2=classify2.groupby(\"Region\")[\"Estimated Unemployment Rate\"].mean()\n",
    "average_of_regions2.plot(kind='pie',autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Region-wise Average Unemployment Rate of year 2020')\n",
    "plt.show()\n",
    "\n",
    "# lets visualize the average of each state and area wise estimated unemployment rate of year 2019\n",
    "filtered_data = classify1[classify1['Area'].isin(['Rural', 'Urban'])]\n",
    "avg_unemployment = filtered_data.groupby(['State', 'Area'])['Estimated Unemployment Rate'].mean().reset_index()\n",
    "\n",
    "figure = px.sunburst(avg_unemployment, path=[\"State\", \"Area\"], values=\"Estimated Unemployment Rate\", \n",
    "                     width=700, height=700, color_continuous_scale=\"RdYlGn\", \n",
    "                     title=\"Average Unemployment Rate by State and Area\")\n",
    "\n",
    "figure.show()\n",
    "\n",
    "# Calculate the average mean of Unemployment rate for each state in the year 2020\n",
    "state_avg_mean = classify2.groupby('State')['Estimated Unemployment Rate'].mean()\n",
    "# Sort the data in ascending order of the average mean\n",
    "state_avg_mean = state_avg_mean.sort_values(ascending=True)\n",
    "\n",
    "# Create a bar plot for the average mean of every state\n",
    "state_avg_mean.plot(kind='bar', figsize=(10, 6))\n",
    "\n",
    "# Set the labels and title of the plot\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Average Mean')\n",
    "plt.title('Average Mean of Every State')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Lets check in which month does every state got highest estimated unemployment rate in year 2019\n",
    "# Convert the 'Date' column to datetime if it's not already in datetime format\n",
    "classify1['Date'] = pa.to_datetime(classify1['Date'])\n",
    "\n",
    "# Extract the month from the 'Date' column and create a new 'Month' column with month names\n",
    "classify1['Month'] = classify1['Date'].dt.strftime('%B')\n",
    "\n",
    "# Find the month with the highest estimated unemployment rate for each state\n",
    "highest_month = classify1.groupby('State')['Estimated Unemployment Rate'].idxmax()\n",
    "highest_month_df = classify1.loc[highest_month, ['State', 'Month', 'Estimated Unemployment Rate']].copy()\n",
    "\n",
    "# Sort the DataFrame by the highest unemployment rate in ascending order\n",
    "highest_month_df.sort_values('Estimated Unemployment Rate', inplace=True)\n",
    "\n",
    "# Create a bar graph to visualize the month with the highest estimated unemployment rate for each state\n",
    "plt.figure(figsize=(18, 15))\n",
    "plt.bar(highest_month_df['State'], highest_month_df['Estimated Unemployment Rate'], color='skyblue')\n",
    "\n",
    "# Add text labels with the month and the corresponding unemployment rate above each bar\n",
    "for x, y, month in zip(highest_month_df['State'], highest_month_df['Estimated Unemployment Rate'], highest_month_df['Month']):\n",
    "    plt.text(x, y, f'{month}\\n{y:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Estimated Unemployment Rate')\n",
    "plt.title('Month with Highest Estimated Unemployment Rate for Each State in year 2019')\n",
    "plt.xticks(rotation=65)\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Lets check in which month does every state got highest estimated unemployment rate in year 2020\n",
    "# Convert the 'Date' column to datetime if it's not already in datetime format\n",
    "classify2['Date'] = pa.to_datetime(classify2['Date'])\n",
    "\n",
    "# Extract the month from the 'Date' column and create a new 'Month' column with month names\n",
    "classify2['Month'] = classify2['Date'].dt.strftime('%B')\n",
    "\n",
    "# Find the month with the highest estimated unemployment rate for each state\n",
    "highest_month2 = classify2.groupby('State')['Estimated Unemployment Rate'].idxmax()\n",
    "highest_month_df2 = classify2.loc[highest_month2, ['State', 'Month', 'Estimated Unemployment Rate']].copy()\n",
    "\n",
    "# Sort the DataFrame by the highest unemployment rate in ascending order\n",
    "highest_month_df2.sort_values('Estimated Unemployment Rate', inplace=True)\n",
    "\n",
    "# Create a bar graph to visualize the month with the highest estimated unemployment rate for each state\n",
    "plt.figure(figsize=(18, 15))\n",
    "plt.bar(highest_month_df2['State'], highest_month_df2['Estimated Unemployment Rate'], color='yellow')\n",
    "\n",
    "# Add text labels with the month and the corresponding unemployment rate above each bar\n",
    "for x, y, month in zip(highest_month_df2['State'], highest_month_df2['Estimated Unemployment Rate'], highest_month_df2['Month']):\n",
    "    plt.text(x, y, f'{month}\\n{y:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Estimated Unemployment Rate')\n",
    "plt.title('Month with Highest Estimated Unemployment Rate for Each State in year 2020')\n",
    "plt.xticks(rotation=65)\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "plt.subplots_adjust(bottom=0.3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Concatenate the two datasets\n",
    "combined_data = pa.concat([classify1, classify2])\n",
    "\n",
    "# Define the order of the months\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "# Convert the 'Month' column to categorical data type with the custom sort order\n",
    "combined_data['Month'] = pa.Categorical(combined_data['Month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Calculate the mean Estimated Unemployment Rate for each month and state\n",
    "monthly_data = combined_data.groupby(['Month', 'State'])['Estimated Unemployment Rate'].mean().reset_index()\n",
    "\n",
    "# Get a list of unique states\n",
    "states = combined_data['State'].unique()\n",
    "\n",
    "# Create separate line plot graphs for each state\n",
    "for state in states:\n",
    "    state_data = monthly_data[monthly_data['State'] == state]\n",
    "    plt.plot(state_data['Month'], state_data['Estimated Unemployment Rate'], label=state)\n",
    "\n",
    "    # Set the x-axis label as 'Month'\n",
    "    plt.xlabel('Month')\n",
    "\n",
    "    # Set the y-axis label as 'Estimated Unemployment Rate'\n",
    "    plt.ylabel('Estimated Unemployment Rate')\n",
    "\n",
    "    # Set the title of the graph\n",
    "    plt.title('Estimated Unemployment Rate for Each State (2019-2020)')\n",
    "\n",
    "    # Add a legend to differentiate the states\n",
    "    plt.legend()\n",
    "\n",
    "    # Rotate the x-axis labels for better visibility\n",
    "    plt.xticks(rotation=65)\n",
    "\n",
    "    # Display the line plot\n",
    "    plt.show()\n",
    "\n",
    "    print(\"From the above data,we can see that the Unemployment rate is very high in the month April-May and low in June-july\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0c735-0d3a-4939-8921-29aeb1bde2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
